{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from random import getrandbits\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction for requesting the page using a payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent':\n",
    "           'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "\n",
    "def get_page(url):\n",
    "        email = 'youremail+{}@gmail.com'.format(getrandbits(40))\n",
    "        payload ={\n",
    "            'form[email:Fi1mS3bZn3VF]': email,\n",
    "            'form[landed_at]': '1500901708', # don't change \n",
    "            'form[language]': 'en', # don't change\n",
    "            'form[terms:QS4P6gmSVp8s]': '1', # don't change\n",
    "            'form[textfield:Boa0BNN75u6R]': 'Amsterdam', # change to ur city\n",
    "            'form[textfield:EKZm78mYLBbE]': 'Streetname 2', # change to ur streetname + number\n",
    "            'form[textfield:IIdtgeMwp8Gp]': 'Fock', # first name\n",
    "            'form[textfield:MQfwQiem4TEw]': '1111AA', # zip code\n",
    "            'form[textfield:bHSS1rapvhha]': 'NikeTalk', # Last name\n",
    "            'form[textfield:n3yXjbpstFmJ]': 'None', # change to ur state, if EU set: None\n",
    "            'form[textfield:u9og65Z22NNB]': 'The Netherlands', # change to ur country\n",
    "            'form[token]': 'e5455f13bd09203c7f5f0b433129e116$2y$11$e2dJZC0zIXZQK1pxbSZbL.LzJE2QS5SFRX2Z7Lk/oL/j6JicEpiXS', # don't change\n",
    "            'form[yes-no:warE3SilldbG]': '1', # don't change\n",
    "                        }\n",
    "        resp = requests.post(url, data=payload, headers=headers)\n",
    "        if any(re.findall(r'succes', str(resp.text), re.IGNORECASE)):\n",
    "            return resp\n",
    "        else:\n",
    "            print(time.strftime(\"%H:%M:%S\") + \" / Could not enter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap all the pages for getting the brand, name, price, availability, url, img and color of all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page : 1\n",
      "Fetching page : 2\n",
      "Fetching page : 3\n",
      "Fetching page : 4\n",
      "Fetching page : 5\n",
      "Fetching page : 6\n",
      "Fetching page : 7\n",
      "Fetching page : 8\n",
      "Fetching page : 9\n",
      "Fetching page : 10\n",
      "Fetching page : 11\n",
      "Fetching page : 12\n",
      "Fetching page : 13\n",
      "Fetching page : 14\n",
      "Fetching page : 15\n",
      "Fetching page : 16\n",
      "Fetching page : 17\n",
      "Fetching page : 18\n",
      "Fetching page : 19\n",
      "Fetching page : 20\n",
      "Fetching page : 21\n",
      "Fetching page : 22\n",
      "Fetching page : 23\n",
      "Fetching page : 24\n",
      "Fetching page : 25\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.sneakersnstuff.com/fr/904/sneakers-homme'\n",
    "page = get_page(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "nb_pages = int(soup.find('span', {'class': 'pagination__total'}).text)\n",
    "\n",
    "all_elmts = []\n",
    "for i in range(1, nb_pages + 1):\n",
    "    print(\"Fetching page : \" + str(i))\n",
    "    page = get_page(url + \"/\" + str(i))\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    articles = soup.find(\"div\", {\"class\": \"product-list\"}).find_all(\"article\")\n",
    "    for article in articles:\n",
    "        elmt = {}\n",
    "        if article.find(\"span\", {\"class\" : \"card__brand\"}) is not None:\n",
    "            elmt[\"brand\"] = article.find(\"span\", {\"class\" : \"card__brand\"}).text\n",
    "        elmt[\"name\"] = article.find(\"strong\", {\"class\": \"card__name\"}).text\n",
    "        elmt[\"price\"] = article.find(\"span\", {\"class\" : \"price__current\"}).text.replace(\"\\n\",\"\").replace(\" EUR\", \"\")\n",
    "        elmt[\"available\"] = article.find(\"div\", {\"class\" : \"card__availability\"}).text.replace(\"\\n\",\"\")\n",
    "        elmt[\"url\"] = \"https://www.sneakersnstuff.com\" + article.find(\"a\", {\"class\" : \"card__link\"})[\"href\"]\n",
    "        elmt[\"img\"] = \"https://www.sneakersnstuff.com\" + article.find(\"img\")[\"src\"]\n",
    "        elmt[\"color\"] = json.loads(article.attrs[\"data-gtm-list-product\"])[\"variant\"]\n",
    "        all_elmts.append(elmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_elmts).to_csv(\"sneakersnstuff.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
